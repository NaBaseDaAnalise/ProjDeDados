if model_name == 'KNN':
            param_grid = {
                'n_neighbors': [9, 13, 15, 20],
                'weights': ['uniform', 'distance'],
                'metric': ['euclidean', 'manhattan']
            }
        elif model_name == 'SVM':
            param_grid = {
                'C': [0.1, 1, 10, 100],
                'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],
                'gamma': ['scale', 'auto']
            }
        elif model_name == 'NeuralNetwork':
            param_grid = {
                'hidden_layer_sizes': [(50,), (100,)],
                'activation': ['relu'],
                'solver': ['sgd'],
                'learning_rate': ['adaptive'],
                'max_iter': [300, 500, 1000],
                'learning_rate_init': [0.001, 0.01]
            }
        elif model_name == 'RandomForest':
            param_grid = {
                'n_estimators': [300, 500],
                'max_depth': [15, 20, None],
                'min_samples_split': [5, 10, 15],
                'min_samples_leaf': [2, 4, 8],
                'bootstrap': [True]
            }
        elif model_name == 'GBT':
            param_grid = {
                'n_estimators': [50, 100],
                'learning_rate': [0.01],
                'max_depth': [3, 4, 10, None],
                'subsample': [1.0],
                'min_samples_split': [5],
                'min_samples_leaf': [1, 2]
            }
        elif model_name == 'LogisticRegression':
            # Definindo os parâmetros que serão utilizados
            param_grid = {
                'penalty': ['elasticnet', None],
                'C': [0.1, 1],
                'solver': ['saga'],
                'l1_ratio': [0.3, 0.5, 0.7]
            }

            # Filtrando combinações válidas
            valid_param_grid = []
            for penalty in param_grid['penalty']:
                if penalty == 'l2':
                    # 'liblinear', 'newton-cg', e 'sag' suportam 'l2'
                    for C_value in param_grid['C']:
                        for solver in ['liblinear', 'newton-cg', 'sag']:
                            valid_param_grid.append({'penalty': [penalty], 'C': [C_value], 'solver': [solver]})
                elif penalty == 'l1':
                    # 'liblinear' e 'saga' suportam 'l1'
                    for C_value in param_grid['C']:
                        for solver in ['liblinear', 'saga']:
                            valid_param_grid.append({'penalty': [penalty], 'C': [C_value], 'solver': [solver]})
                elif penalty == 'elasticnet':
                    # Apenas 'saga' suporta 'elasticnet'
                    for C_value in param_grid['C']:
                        for l1_ratio_value in [0.1, 0.5, 0.9]:  # Adicionando valores para 'l1_ratio'
                            valid_param_grid.append({
                                'penalty': [penalty],
                                'C': [C_value],
                                'solver': ['saga'],
                                'l1_ratio': [l1_ratio_value]
                            })
                elif penalty == 'none':
                    # 'saga' e 'newton-cg' suportam 'none'
                    for solver in ['saga', 'newton-cg']:
                        valid_param_grid.append({'penalty': [penalty], 'solver': [solver]})

            # Convertendo para o formato esperado pelo GridSearchCV
            param_grid = []
            for item in valid_param_grid:
                if item['penalty'] == ['elasticnet']:
                    param_grid.append({'penalty': item['penalty'], 'C': item['C'], 'solver': item['solver'], 'l1_ratio': item['l1_ratio']})
                elif 'C' in item:
                    param_grid.append({'penalty': item['penalty'], 'C': item['C'], 'solver': item['solver']})
                else:
                    param_grid.append({'penalty': item['penalty'], 'solver': item['solver']})



        elif model_name == 'AdaBoost':
            param_grid = {
                'n_estimators': [100, 200, 300],
                'learning_rate': [0.5, 1.0,1.5]
            }
        elif model_name == 'ExtraTrees':
            param_grid = {
                'n_estimators': [100, 200, 300],
                'max_depth': [13,15, 17, None],
                'min_samples_split': [4, 5, 9],
                'min_samples_leaf': [1],
                'bootstrap': [False]
            }
        elif model_name == 'XGBoost':
            param_grid = {
                'n_estimators': [50, 100, 200],
                'learning_rate': [0.01, 0.1],
                'max_depth': [2, 3, 7],
                'subsample': [1.0],
                'colsample_bytree': [0.6, 0.8]
            }
        elif model_name == 'CatBoost':
            param_grid = {
                'iterations': [250, 500],
                'learning_rate': [0.01],
                'depth': [2, 4, 6],
                'l2_leaf_reg': [5, 7]
            }
